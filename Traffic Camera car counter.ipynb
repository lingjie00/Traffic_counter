{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:18.260014Z",
     "iopub.status.busy": "2020-10-08T14:49:18.259737Z",
     "iopub.status.idle": "2020-10-08T14:49:22.081768Z",
     "shell.execute_reply": "2020-10-08T14:49:22.081133Z",
     "shell.execute_reply.started": "2020-10-08T14:49:18.259948Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time\n",
    "\n",
    "# For downloading the traffic camera photo\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:23.360296Z",
     "iopub.status.busy": "2020-10-08T14:49:23.360084Z",
     "iopub.status.idle": "2020-10-08T14:49:23.373900Z",
     "shell.execute_reply": "2020-10-08T14:49:23.373286Z",
     "shell.execute_reply.started": "2020-10-08T14:49:23.360274Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image)\n",
    "\n",
    "def draw_title(image,font,title):\n",
    "    \"\"\"Draw the title\"\"\"\n",
    "    im_width, im_height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    w, h = font.getsize(title)\n",
    "    # draw a box\n",
    "    draw.rectangle((10, im_height-50, 10 + w, im_height-50 + h * 2.5), fill = 'black')\n",
    "    # draw the title\n",
    "    draw.multiline_text((10, im_height-50), title, font=font, fill=(255,255,255))\n",
    "    \n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()\n",
    "                              ):\n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    # box exceeds the top of the image, stack the strings below the bounding box\n",
    "    # instead of above.\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                        (left + text_width, text_bottom)],\n",
    "                       fill=color)\n",
    "        draw.text((left + margin, text_bottom - text_height - margin),\n",
    "                  display_str,\n",
    "                  fill=\"black\",\n",
    "                  font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, title, max_boxes=10, min_score=0.1):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/Users/lingjie/Library/Fonts/JosefinSansLight-ZVEll.ttf\", 20)\n",
    "    except IOError:\n",
    "        print(\"Font not found, using default font.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                         int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i]) % len(colors)]\n",
    "            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "            draw_bounding_box_on_image(image_pil,ymin,xmin,ymax,xmax,color,font,display_str_list=[display_str])\n",
    "            np.copyto(image, np.array(image_pil))\n",
    "            \n",
    "    image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "    draw_title(image_pil,font, title)\n",
    "    np.copyto(image, np.array(image_pil))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:24.155796Z",
     "iopub.status.busy": "2020-10-08T14:49:24.155603Z",
     "iopub.status.idle": "2020-10-08T14:49:24.159886Z",
     "shell.execute_reply": "2020-10-08T14:49:24.159191Z",
     "shell.execute_reply.started": "2020-10-08T14:49:24.155775Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_url(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    title = soup.title.string\n",
    "    links = soup.find_all('img')\n",
    "    img_links = {}\n",
    "    for link in links:\n",
    "        if 'View from' in link.get('alt'):\n",
    "            img_links[link.get('alt')] = 'http://' + link.get('src').replace('//', '')\n",
    "    return img_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:24.472966Z",
     "iopub.status.busy": "2020-10-08T14:49:24.472729Z",
     "iopub.status.idle": "2020-10-08T14:49:24.477002Z",
     "shell.execute_reply": "2020-10-08T14:49:24.476068Z",
     "shell.execute_reply.started": "2020-10-08T14:49:24.472939Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_img(img_url):\n",
    "    img = requests.get(img_url, stream=True)\n",
    "    image_data = BytesIO(img.content)\n",
    "    pil_image = Image.open(image_data)\n",
    "#     pil_image = ImageOps.fit(pil_image, (512, 512), Image.ANTIALIAS) # resize photo\n",
    "    return pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:24.785698Z",
     "iopub.status.busy": "2020-10-08T14:49:24.785501Z",
     "iopub.status.idle": "2020-10-08T14:49:24.791937Z",
     "shell.execute_reply": "2020-10-08T14:49:24.791256Z",
     "shell.execute_reply.started": "2020-10-08T14:49:24.785677Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_detector_car(detector, img_link):\n",
    "    img = get_img(img_link)\n",
    "    img_np = np.array(img)\n",
    "    converted_img = tf.convert_to_tensor(img_np)\n",
    "    converted_img  = tf.image.convert_image_dtype(converted_img, tf.float32)[tf.newaxis, ...]\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "\n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "    \n",
    "    car_index = (np.isin(np.array(result[\"detection_class_entities\"], dtype='str'), \n",
    "                         ['Car', 'Vehicle', 'Land vehicle', 'Motorcycle'])) & (result[\"detection_scores\"] >= 0.1) # min score\n",
    "\n",
    "#     print(\"Found %d cars.\" % len(result[\"detection_scores\"][car_index]))\n",
    "#     print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "    title = 'Found {} cars.\\nInference time: {}'.format(len(result[\"detection_scores\"][car_index]), end_time-start_time)\n",
    "    \n",
    "    image_with_boxes = draw_boxes(\n",
    "        np.array(img_np, np.int32), result[\"detection_boxes\"][car_index],\n",
    "        result[\"detection_class_entities\"][car_index], result[\"detection_scores\"][car_index],\n",
    "        title\n",
    "    )\n",
    "\n",
    "#     display_image(image_with_boxes)\n",
    "    return {'num_cars' : len(result[\"detection_scores\"][car_index]), 'time_taken' : end_time-start_time, 'img' : image_with_boxes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:25.191690Z",
     "iopub.status.busy": "2020-10-08T14:49:25.191467Z",
     "iopub.status.idle": "2020-10-08T14:49:25.194969Z",
     "shell.execute_reply": "2020-10-08T14:49:25.194230Z",
     "shell.execute_reply.started": "2020-10-08T14:49:25.191668Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_camera():\n",
    "    traffic_cameras = {}\n",
    "    for url in urls:\n",
    "        traffic_cameras.update(get_url(url))\n",
    "    return traffic_cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:25.526185Z",
     "iopub.status.busy": "2020-10-08T14:49:25.525966Z",
     "iopub.status.idle": "2020-10-08T14:49:42.648189Z",
     "shell.execute_reply": "2020-10-08T14:49:42.647682Z",
     "shell.execute_reply.started": "2020-10-08T14:49:25.526163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
    "\n",
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:42.650007Z",
     "iopub.status.busy": "2020-10-08T14:49:42.649702Z",
     "iopub.status.idle": "2020-10-08T14:49:42.654571Z",
     "shell.execute_reply": "2020-10-08T14:49:42.653823Z",
     "shell.execute_reply.started": "2020-10-08T14:49:42.649980Z"
    }
   },
   "outputs": [],
   "source": [
    "woodlands = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/woodlands.html#trafficCameras'\n",
    "kje = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/kje.html#trafficCameras'\n",
    "sle = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/sle.html#trafficCameras'\n",
    "tpe = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/tpe.html#trafficCameras'\n",
    "bke = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/bke.html#trafficCameras'\n",
    "aye = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/aye.html#trafficCameras'\n",
    "cte = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/cte.html#trafficCameras'\n",
    "mce = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/mce.html#trafficCameras'\n",
    "ecp = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/ecp.html#trafficCameras'\n",
    "pie = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/pie.html#trafficCameras'\n",
    "stg = 'https://www.onemotoring.com.sg/content/onemotoring/home/driving/traffic_information/traffic-cameras/stg.html#trafficCameras'\n",
    "urls = [woodlands, kje, sle, tpe, bke, aye, cte, mce, ecp, pie, stg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:49:42.656603Z",
     "iopub.status.busy": "2020-10-08T14:49:42.656403Z",
     "iopub.status.idle": "2020-10-08T14:49:45.433684Z",
     "shell.execute_reply": "2020-10-08T14:49:45.433173Z",
     "shell.execute_reply.started": "2020-10-08T14:49:42.656581Z"
    }
   },
   "outputs": [],
   "source": [
    "traffic_cameras = update_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:53:13.583616Z",
     "iopub.status.busy": "2020-10-08T14:53:13.576287Z",
     "iopub.status.idle": "2020-10-08T14:53:13.620373Z",
     "shell.execute_reply": "2020-10-08T14:53:13.618747Z",
     "shell.execute_reply.started": "2020-10-08T14:53:13.583547Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, [ax1, ax2, ax3, ax4, ax5] = plt.subplots(5, 5, figsize=(20,20), dpi=100, gridspec_kw={'hspace':0})\n",
    "# for ax, cam, title in zip(ax1, list(traffic_cameras.values())[:5], list(traffic_cameras.keys())[:5]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax2, list(traffic_cameras.values())[5:10], list(traffic_cameras.keys())[5:10]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax3, list(traffic_cameras.values())[10:15], list(traffic_cameras.keys())[10:15]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax4, list(traffic_cameras.values())[15:20], list(traffic_cameras.keys())[15:20]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax5, list(traffic_cameras.values())[20:25], list(traffic_cameras.keys())[20:25]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:50:49.521996Z",
     "iopub.status.busy": "2020-10-08T14:50:49.521761Z",
     "iopub.status.idle": "2020-10-08T14:50:49.525656Z",
     "shell.execute_reply": "2020-10-08T14:50:49.524801Z",
     "shell.execute_reply.started": "2020-10-08T14:50:49.521971Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig.savefig('output/traffic_cam.jpg', dpi=600, bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:50:49.527705Z",
     "iopub.status.busy": "2020-10-08T14:50:49.527457Z",
     "iopub.status.idle": "2020-10-08T14:50:49.530530Z",
     "shell.execute_reply": "2020-10-08T14:50:49.529816Z",
     "shell.execute_reply.started": "2020-10-08T14:50:49.527681Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig2, [ax1, ax2, ax3, ax4, ax5] = plt.subplots(5, 5, figsize=(20,20), dpi=300, gridspec_kw={'hspace':0})\n",
    "# for ax, cam, title in zip(ax1, list(traffic_cameras.values())[25:30], list(traffic_cameras.keys())[25:30]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax2, list(traffic_cameras.values())[30:35], list(traffic_cameras.keys())[30:35]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax3, list(traffic_cameras.values())[35:40], list(traffic_cameras.keys())[35:40]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax4, list(traffic_cameras.values())[40:45], list(traffic_cameras.keys())[40:45]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax5, list(traffic_cameras.values())[45:50], list(traffic_cameras.keys())[45:50]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# fig2.savefig('output/traffic_cam2.jpg', dpi=600, bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:50:49.534107Z",
     "iopub.status.busy": "2020-10-08T14:50:49.533853Z",
     "iopub.status.idle": "2020-10-08T14:50:49.536966Z",
     "shell.execute_reply": "2020-10-08T14:50:49.536297Z",
     "shell.execute_reply.started": "2020-10-08T14:50:49.534082Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig3, [ax1, ax2, ax3, ax4, ax5] = plt.subplots(5, 5, figsize=(20,20), dpi=300, gridspec_kw={'hspace':0})\n",
    "# for ax, cam, title in zip(ax1, list(traffic_cameras.values())[50:55], list(traffic_cameras.keys())[50:55]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax2, list(traffic_cameras.values())[55:60], list(traffic_cameras.keys())[55:60]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax3, list(traffic_cameras.values())[60:65], list(traffic_cameras.keys())[60:65]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax4, list(traffic_cameras.values())[65:70], list(traffic_cameras.keys())[65:70]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax5, list(traffic_cameras.values())[70:75], list(traffic_cameras.keys())[70:75]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# fig3.savefig('output/traffic_cam3.jpg', dpi=600, bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-08T14:50:49.539812Z",
     "iopub.status.busy": "2020-10-08T14:50:49.539597Z",
     "iopub.status.idle": "2020-10-08T14:50:49.542270Z",
     "shell.execute_reply": "2020-10-08T14:50:49.541630Z",
     "shell.execute_reply.started": "2020-10-08T14:50:49.539789Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig4, [ax1, ax2] = plt.subplots(2, 4, figsize=(20,20), dpi=300, gridspec_kw={'hspace':0})\n",
    "# for ax, cam, title in zip(ax1, list(traffic_cameras.values())[75:79], list(traffic_cameras.keys())[75:79]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# for ax, cam, title in zip(ax2, list(traffic_cameras.values())[78:82], list(traffic_cameras.keys())[78:82]):\n",
    "#     ax.axis('off')\n",
    "#     result = run_detector_car(detector, cam)\n",
    "#     ax.imshow(result['img'])\n",
    "#     ax.set_title(title, fontdict={'fontsize':8})\n",
    "# ax2[-1].axis('off')\n",
    "# fig4.savefig('output/traffic_cam4.jpg', dpi=600, bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
